{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading iris Data set\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Ionosphere Dataset\n",
    "import numpy as np\n",
    "X = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",usecols=np.arange(5)) \n",
    "#Extracting all the features\n",
    "\n",
    "y = np.genfromtxt(\"ionosphere.txt\", delimiter=\",\",usecols=34, dtype='int')\n",
    "#Extracting all the Labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #scikit-learn has ML models\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(iris['data'],\n",
    "iris['target'], random_state=106)\n",
    "#train_test_split function to divide the iris data in 75 % training set and 25 % as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  #scikit-learn has ML models\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X,y, random_state=106)\n",
    "#train_test_split function to divide the ionosphere data in 75 % training set and 25 % as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict labels using 1NN\n",
    "def NNpredict(TrainSample,TrainLabel,test): #Use Train Sample, train Label and Test Sample as parameter\n",
    "    Distance_array=[] #store distances from each test sample\n",
    "    predicted_label=[] #array to store predicted labels\n",
    "    b=[] #to store feature points of test sample\n",
    "    a=[] #to store feature points of train sample sample\n",
    "    test_rows=test.shape[0]  #storing no of rows test sample\n",
    "    test_cols=test.shape[1]  #storing no of columns of test sample\n",
    "    k=0 #to iterate test Samples\n",
    "    while(k<test_rows): # iterate in while until distances from all test samples is calculated\n",
    "        for p in range(test_cols):\n",
    "            b.append(test[k][p])   #add every point in test sample to array \n",
    "        train_rows = TrainSample.shape[0] #storing no of rows train sample\n",
    "        train_cols = TrainSample.shape[1] #storing no of rows train sample\n",
    "        for i in range(train_rows): #computing distances from each train sample\n",
    "            for j in range(train_cols):\n",
    "                a.append(TrainSample[i][j]) #add every point in train sample to array \n",
    "            m=0\n",
    "            sum=0\n",
    "            for r in range(train_cols):\n",
    "                sum=sum+((a[r]-b[r])**2) #Eucleadian distance formula\n",
    "            d = np.sqrt(sum)\n",
    "            Distance_array.append(d) #append each distance to array\n",
    "            a.clear() #reset train array\n",
    "        minimum=Distance_array.index(min(Distance_array)) #return the index with the minimum distance\n",
    "        predicted_label.append(TrainLabel[minimum]) #store the label at that index value\n",
    "        Distance_array.clear() #rest distance array\n",
    "        b.clear() #reset test array\n",
    "        k=k+1 #increment for next test sample\n",
    "    return predicted_label #return the set of predicted labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my Function for Iris Dataset is:  0.9736842105263158\n",
      "Number of Errors are:  1\n",
      "Test Error Rate is:  0.02631578947368418\n"
     ]
    }
   ],
   "source": [
    "#Iris Dataset\n",
    "y_pred1 = NNpredict(X_train1,y_train1,X_test1) #training iris dataset\n",
    "accuracy=np.mean(y_pred1 == y_test1) #find accuracy\n",
    "n=y_test1.shape[0] #store number of rows\n",
    "count=0 # count for number of errors\n",
    "for i in range(n):\n",
    "    if(y_pred1[i]!=y_test1[i]): # check if labels not same\n",
    "        count=count+1 # if not add a count\n",
    "print(\"Accuracy of my Function for Iris Dataset is: \",accuracy) #print accuracy\n",
    "print(\"Number of Errors are: \",count) #print number of errors\n",
    "print(\"Test Error Rate is: \",1-accuracy) # print error rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of my Function for Ionosphere Dataset is:  0.875\n",
      "Number of Errors are:  11\n",
      "Test Error Rate is:  0.125\n"
     ]
    }
   ],
   "source": [
    "#Ionosphere Dataset\n",
    "y_pred2 = NNpredict(X_train2,y_train2,X_test2) #training ionosphere dataset\n",
    "accuracy=np.mean(y_pred2 == y_test2) #find accuracy\n",
    "n=y_test2.shape[0] #store number of rows\n",
    "count=0 # count for number of errors\n",
    "for i in range(n):\n",
    "    if(y_pred2[i]!=y_test2[i]): # check if labels not same\n",
    "        count=count+1 # if not add a count\n",
    "print(\"Accuracy of my Function for Ionosphere Dataset is: \",accuracy) #print accuracy\n",
    "print(\"Number of Errors are: \",count) #print number of errors\n",
    "print(\"Test Error Rate is: \",1-accuracy) # print Test error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is of Inbuilt Method:  0.9736842105263158\n",
      "Error Rate is of Inbuilt Method:  0.02631578947368418\n"
     ]
    }
   ],
   "source": [
    "#Iris Dataset\n",
    "#Comparing Our Function Results with Inbuilt Method \n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN is in neighbors module in Scikit learn\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train1,y_train1)\n",
    "y_pred = knn.predict(X_test1)\n",
    "m=np.mean(y_pred == y_test1)\n",
    "print(\"Accuracy is of Inbuilt Method: \",m)\n",
    "print(\"Error Rate is of Inbuilt Method: \",1-m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is of Inbuilt Method:  0.875\n",
      "Error Rate is of Inbuilt Method:  0.125\n"
     ]
    }
   ],
   "source": [
    "#Ionosphere Dataset\n",
    "#Comparing Our Function Results with Inbuilt Method\n",
    "from sklearn.neighbors import KNeighborsClassifier #KNN is in neighbors module in Scikit learn\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train2,y_train2)\n",
    "y_pred = knn.predict(X_test2)\n",
    "m=np.mean(y_pred == y_test2)\n",
    "print(\"Accuracy is of Inbuilt Method: \",m)\n",
    "print(\"Error Rate is of Inbuilt Method: \",1-m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
